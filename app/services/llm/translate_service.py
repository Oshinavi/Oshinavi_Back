# app/services/llm/translate_service.py

import logging
import re
from typing import List
from openai import AsyncOpenAI
from app.services.llm.prompts import PromptType, SYSTEM_PROMPTS
from app.services.llm.rag_service import RAGService
from app.schemas.llm_schema import TranslationResult

logger = logging.getLogger(__name__)

class TranslateService:
    def __init__(
        self,
        openai_client: AsyncOpenAI,
        rag: RAGService,
        model: str = "gpt-4o-mini-2024-07-18"
    ):
        self.openai = openai_client
        self.rag    = rag
        self.model  = model

    async def translate(self, tweet_text: str, tweet_timestamp: str) -> TranslationResult:
        # 1) RAG ë¡œë¶€í„° ê³ ìœ ëª…ì‚¬ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        contexts = self.rag.get_context(tweet_text)
        context_block = "\n".join(f"- {c}" for c in contexts)

        # 2) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        system = SYSTEM_PROMPTS[PromptType.TRANSLATE].format(timestamp=tweet_timestamp)
        enriched = (
            system
            + "\n\n### Reference dictionary:\n"
            + context_block
            + "\n\n"
        )

        try:
            # 3) OpenAI Chat API í˜¸ì¶œ
            resp = await self.openai.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": enriched},
                    {"role": "user",   "content": tweet_text.strip()},
                ],
                temperature=0.3
            )
            content = resp.choices[0].message.content.strip()
            logger.info("[TranslateService] â–¶ Raw LLM response:\n%s", content)

            # 4) ã€Œã€ ì•ˆì˜ '/'ë§Œ íŠ¹ìˆ˜ë¬¸ìë¡œ ë§ˆìŠ¤í‚¹ â†’ ì™¸ë¶€ '/' ë¡œ ë¶„í•  â†’ ë§ˆìŠ¤í‚¹ ë³µì›
            parts = [p.strip() for p in self._split_ignore_brackets(content)]
            if len(parts) != 4:
                raise ValueError(
                    f"ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: 'ë²ˆì—­ë¬¸ / ë¶„ë¥˜ / ì‹œì‘ ì¼ì / ì¢…ë£Œ ì¼ì' ë„¤ ê°œë¡œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. (got {len(parts)} parts)"
                )

            translated, category, start_str, end_str = parts
            start = None if start_str.lower() == "none" else start_str
            end   = None if end_str.lower()   == "none" else end_str

            logger.info(
                "[TranslateService] â–¶ Parsed fields:\n"
                "   ë²ˆì—­ë¬¸ : %s\n"
                "   ë¶„ë¥˜   : %s\n"
                "   ì‹œì‘ì¼ì: %s\n"
                "   ì¢…ë£Œì¼ì: %s",
                translated, category, start, end
            )

            return TranslationResult(
                translated=translated,
                category=category,
                start=start,
                end=end,
            )

        except Exception as e:
            logger.error("LLM translate error: %s", e, exc_info=True)
            raise

    def _split_ignore_brackets(self, text: str) -> List[str]:
        """
        1) ã€Œâ€¦ã€ ë¸”ë¡ ì•ˆì˜ '/' ë¥¼ U+E000 ì˜ì—­ìœ¼ë¡œ ë§ˆìŠ¤í‚¹
        2) ë‚¨ì€ '/' ë¡œë§Œ text.split('/')
        3) ë§ˆìŠ¤í‚¹ëœ ë¬¸ìë¥¼ ì›ë˜ '/' ë¡œ ë³µì›
        """
        # 1) mask slashes inside ã€Œâ€¦ã€
        def _mask(m: re.Match) -> str:
            return m.group(0).replace('/', '\ue000')

        masked = re.sub(r'ã€Œ[^ã€]*ã€', _mask, text)
        # 2) ì™¸ë¶€ ìŠ¬ë˜ì‹œë¡œ ë¶„í• 
        raw_parts = masked.split('/')
        # 3) ë§ˆìŠ¤í‚¹ì„ ë‹¤ì‹œ ìŠ¬ë˜ì‹œë¡œ
        return [part.replace('\ue000', '/') for part in raw_parts]



# import re
# import logging
# from typing import Optional, Dict
# from app.utils.ollama_client import OllamaClient
# from app.services.ai.rag_service import RAGService
# from app.core.config import settings
#
# logger = logging.getLogger(__name__)
#
# ollama = OllamaClient(settings.ollama_api_url, settings.ollama_model)
#
# rag = RAGService(
#     index_path="vector_store/faiss_index.bin",
#     meta_path="vector_store/metadata.json",
#     embedding_model_name="sentence-transformers/all-MiniLM-L6-v2",
#     top_k=3
# )
#
# SYSTEM_PROMPT = """
# You are an AI that processes Japanese tweets along with their timestamps.
# Tweet was posted on: {timestamp}
#
# Your tasks are:
# - Translate the tweet into Korean while keeping hashtags in their original Japanese form.
# - Identify whether the tweet is about one of the following categories: ì¼ë°˜, ë°©ì†¡, ë¼ë””ì˜¤, ë¼ì´ë¸Œ, ìŒë°˜, êµ¿ì¦ˆ, ì˜ìƒ, ê²Œì„.
# - ONLY IF the tweet explicitly includes a date or time:
#     â€¢ an absolute date/time (e.g. '5/5(æœˆ) 20:30') or
#     â€¢ a relative date immediately followed by a time (e.g. 'ä»Šæ—¥20æ™‚') or
#     â€¢ a â€œï½ã¾ã§â€ expression indicating an end bound (e.g. 'ä»Šæ—¥ã¾ã§', 'æ˜æ—¥ã¾ã§')
#     â€¢ a â€œï½ã‹ã‚‰â€ expression indicating a start bound (e.g. 'æ˜æ—¥15æ™‚ã‹ã‚‰', '5/5 10:00ã‹ã‚‰')
#     â€¢ Extract it in the format 'YYYY.MM.DD HH:MM:SS'.
#     â€¢ To resolve relative dates like:
#         â€“ 'æ˜æ—¥' alone, only if paired with a time (e.g. 'æ˜æ—¥15æ™‚').
#         â€“ '~ã¾ã§': treat as an **end date/time** at that dayâ€™s 23:59:59.
#         â€“ 'ï½ã‹ã‚‰': treat as a **start date/time** at the specified moment.
#     â€¢ If only a start date/time is present, set the end date/time to exactly one hour after the start.
#     â€¢ If only an end date/time is present, set the start date/time to that day at 00:00:00.
#     â€¢ If both start and end date/times are present, use them as given.
#   If no date/time information is present, output None for both.
# - If the tweet is not about ì¼ë°˜ or êµ¿ì¦ˆ, specify the related program, event, or media in Korean.
# - Do not add emojis that are not in the original text.
#
# Format your response exactly as:
#   ë²ˆì—­ë¬¸ / ë¶„ë¥˜ / ì‹œì‘ ì¼ì / ì¢…ë£Œ ì¼ì
# """
#
#
# async def translate_japanese_tweet(tweet_text: str, tweet_timestamp: str) -> Dict[str, Optional[str]]:
#     """
#     ì¼ë³¸ì–´ íŠ¸ìœ—ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³ , ì¹´í…Œê³ ë¦¬ ë° ì¼ì • ì •ë³´ ì¶”ì¶œ
#
#     :param tweet_text: íŠ¸ìœ— ì›ë¬¸
#     :param tweet_timestamp: íŠ¸ìœ—ì˜ ì›ë³¸ íƒ€ì„ìŠ¤íƒ¬í”„
#     :return: ë²ˆì—­, ë¶„ë¥˜, ì‹œì‘ì¼, ì¢…ë£Œì¼ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
#     """
#     # RAGë¥¼ í†µí•´ ê³ ìœ ëª…ì‚¬ ì‚¬ì „ì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
#     contexts = rag.get_context(tweet_text)
#     context_block = "\n".join(f"- {c}" for c in contexts)
#     enriched_system = SYSTEM_PROMPT.format(timestamp=tweet_timestamp) + "\n\n" + \
#         "### Reference dictionary:\n" + context_block + "\n\n"
#
#     # ë©”ì‹œì§€ ì¡°í•©
#     messages = [
#         {"role": "system", "content": enriched_system},
#         {"role": "user", "content": tweet_text.strip()}
#     ]
#
#     try:
#         result = await ollama.chat(messages, temperature=0.3)
#         logger.info(f"ğŸ” Ollama ì‘ë‹µ: {result}")
#
#         # ì‘ë‹µ í¬ë§· í™•ì¸ ë° ë¶„ë¦¬
#         parts = [p.strip() for p in re.split(r"\s*/\s*", result)]
#         if len(parts) != 4:
#             raise ValueError("ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: 'ë²ˆì—­ë¬¸ / ë¶„ë¥˜ / ì‹œì‘ ì¼ì / ì¢…ë£Œ ì¼ì'")
#
#         translated, category, start_raw, end_raw = parts
#         return {
#             "translated": translated,
#             "category": category,
#             "start": None if start_raw.lower() == "none" else start_raw,
#             "end": None if end_raw.lower() == "none" else end_raw
#         }
#
#
#     except Exception as e:
#         logger.error(f"â— ë³€í™˜ ì˜¤ë¥˜: {e}")
#         return {
#             "translated": None,
#             "category": None,
#             "start": None,
#             "end": None,
#             "error": str(e)
#         }